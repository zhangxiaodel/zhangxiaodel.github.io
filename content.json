{"pages":[{"title":"","text":"@media screen and (min-width: 1280px) { .container { max-width: 1400px; } .column.is-3-widescreen { flex: none; width: 15%; } .column.is-3-widescreen { flex: none; width: 15%; } .column.is-6-widescreen { flex: none; width: 65%; } }","link":"/css/custom.css"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"HashedDict","text":"自定义字典1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 class HashedDict(object): ''' 自定义hashtable ''' def __init__(self, size=10): self.hash_list = [list() for _ in range(size)] self.size = size self.length = 0 def __setitem__(self, key, value): hash_key = hash(key) % self.size sub_list = self.hash_list[hash_key] if sub_list: # hash冲突时使用list向后追加元素 matched=False for item in sub_list: if item[0] == key: item[1] = value matched=True if not matched: sub_list.append([key, value]) self.length += 1 else: sub_list.append([key, value]) self.length += 1 def __getitem__(self, key): sub_list = self.hash_list[hash(key) % self.size] if sub_list: for item in sub_list: if item[0] == key: return item[1] raise KeyError(key) def __contains__(self, key): sub_list = self.hash_list[hash(key) % self.size] for item in sub_list: if item[0] == key: return True return False def __repr__(self): result = [] for sub_list in self.hash_list: for item in sub_list: result.append(str(item[0] + &quot;:&quot; + str(item[1]))) return &quot;,&quot;.join(result) def items(self): for sub_list in self.hash_list: if not sub_list: continue for innitem in sub_list: yield innitem def values(self): for sub_list in self.hash_list: if not sub_list: continue for innitem in sub_list: yield innitem[1] def __len__(self): return self.length def __str__(self): return self.__repr__() test123456789101112 def test_it(): print('test begin') dd = HashedDict() dd['a'] = 1 dd['b'] = 2 print(dd) print(len(dd)) print(repr(dd)) print(list(dd.items())) print(list(dd.values())) print('test end')","link":"/2020/07/24/HashedDict/"},{"title":"数据导出\\导入","text":"mysqldump -t 只导出数据 ,不导结构 , --skip-lock-tables 不锁表 mysqldump -h127.0.0.1 -P3306 -uuser -ppwd -t --skip-lock-tables test tab1&gt;tab1.sql -d 只备份结构 --skip-add-drop-table 禁用drop tabe(默认会有drop table) mysqldump -hlocalhost -P3306 -uuser -ppwd -d --skip-add-drop-table test tab1&gt; test.tab1.sql 整库备份 mysqldump -hlocalhost -P3306 -uuser -ppwd -B test &gt; test.sql 重要参数 1234567891011-B：指定多个库，在备份文件中增加建库语句和use语句--compact：去掉备份文件中的注释，适合调试，生产场景不用-A：备份所有库-F：刷新binlog日志--master-data：在备份文件中增加binlog日志文件名及对应的位置点-x --lock-all-tables：锁表-l：只读锁表-d：只备份表结构-t：只备份数据--single-transaction：适合innodb事务数据库的备份 InnoDB表在备份时，通常启用选项--single-transaction来保证备份的一致性，原理是设定本次会话的隔离级别为Repeatable read，来保证本次会话（也就是dump）时，不会看到其它会话已经提交了的数据。 导入备份数据 命令行导入 mysql -hlocalhost -P3306 -uuser -ppwd test &lt; test.test.sql 查询 命令行查询 mysql -hlocalhost -P3306 -uroot -p123456 -e &quot;use test; set names utf8; select * from img_library limit 10;&quot; &gt; tmp.xls","link":"/2019/08/11/db-1/"},{"title":"celery分布式异步任务队列","text":"celery是一个基于分布消息传递的异步任务队列.它一定需要建立在一个分布的消息传递机制上，这个消息传递机制就是celery文档里常说的broker。 celery隐藏了rabbitmq接口的实现细节，既充当了publisher（client）又充当了consumer (worker)的角色。 '''思考一下，如果我们用rabbitmq自己实现任务队列，有一天我们不想用rabbit了怎么办？我们换个思维，如果没有celery，让你自己设计一个异步任务队列你怎么做。首先，要有一个发起任务的client，选定一定保存任务信息的媒介，由一个worker去一直监听这个信息媒介，这个worker最好是多进程的，另外可以兼容尽可能多得信息媒介。好吧，这个不就是celery所做的事儿么，celery兼容多个broker，既是任务发起者又是执行者，另外支持多进程…还有好多通用功能考虑。''' 假设项目的目录结构是: 12task-- --celeryapp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 启动消费者celery -A task.celeryapp worker -l info -c 5# 消费者异常退出后 ,正常情况下重启后会继续消息已经积压的任务, 看情况要将过期任务清除# 启动web监控celery -A task.celeryapp flower -l info --basic_auth=user1:111111flower -A task.celeryapp --port=8091# 启动Beat进程,定时任务, 定时将任务发送到brokercelery beat -A task.celeryapp -l info# 同时启动 消费者和定时任务celery -B -A task.celeryapp worker -l info# 也可以在当前目录的上一层来启动 需指定 package.celeryapp# 后台启动 定时任务和消费者celery multi restart w1 -B -A task.celeryapp -l info# celery status -A celery_taskcelery -A task.celeryapp inspect stats# celery.send_task()这个方法解决了producer和consumer的网路拓扑传递数据问题。celery=Celery()celery.config_from_object('task.celeryconfig')celery.send_task('tq.tasks.test', (&quot;hello world&quot;,))# 一般调用方法from task.tasks import testprint test.delay('param from invoke ')# 停止正在执行的任务# 使用方法名调用 可以避免依赖方法的实现代码...celery.config_from_object('task.celeryconfig')from celery.task.control import revokerevoke('aac00b9c-f701-4a21-bed4-53a8b865a39a', terminate=True)from celery.result import AsyncResultres=AsyncResult(t.task_id)res.state&lt;!----&gt;res.revoke(terminate=True)# 配置信息json.dumps(celeryapp.control.inspect().conf(), indent=2)# 已注册的任务列表(得到的列表可以在web页面上做处理, 文件手动触发)celeryapp.control.inspect().registered_tasks()# 任务执行情况celeryapp.control.inspect().active()# 任务执行情况celeryapp.control.inspect().stats() 123在使用flower时遇到 'stats' inspect method failed , 最终通安装指定版本的kombu 解决 4.5.0pipenv install kombu==4.5.0","link":"/2019/10/18/celery-123/"},{"title":"pyenv python2.7&#x2F;3.6 共存&#x2F;切换实践","text":"在docker(python27) 环境中 参考 简书-pyenv 让 python 版本完美切换 更多见github/pyenv-virtualenv 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667docker search python&gt;&gt; ...docker pull centos/python-27-centos7docker images&lt;!--运行docker 环境 --&gt;docker run -i -t centos/python-27-centos7 /bin/bash&lt;!--继续配置环境... --&gt;&lt;!--首先把项目克隆下来，放在家目录下的隐藏文件夹中：.pyenv--&gt;git clone https://github.com/pyenv/pyenv.git ~/.pyenv&lt;!--配置环境变量 ,依次执行如下命令--&gt;echo 'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;' &gt;&gt; ~/.bashrcecho 'export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;' &gt;&gt; ~/.bashrcecho -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval &quot;$(pyenv init -)&quot;\\nfi' &gt;&gt; ~/.bashrc&lt;!--安装 pyenv-virtualenv--&gt;&lt;!--插件克隆在刚才已经安装完毕的 pyenv 的 plugins 文件夹中--&gt;git clone https://github.com/pyenv/pyenv-virtualenv.git $(pyenv root)/plugins/pyenv-virtualenvecho 'eval &quot;$(pyenv virtualenv-init -)&quot;' &gt;&gt; ~/.bashrcsource ~/.bashrc&lt;!--开始使用 pyenv--&gt;pyenv version/versions(查看本地安装的python版本)&lt;!-- pyenv install 敲tag ,可列出支持的版本 --&gt;pyenv install 3.6.8&lt;!--如果失败,可安装依赖的包--&gt;sudo yum install gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel tk-devel libffi-develpyenv versions&lt;!--pyenv 托管 python 版本，virtualenv 使用 python 版本--&gt;&lt;!--创建虚拟环境--&gt;pyenv virtualenv 3.6.8 venv3.6.8&lt;!--激活, 在docker中,发现activate 并不能成功切换环境 ,最终使用 local 可以完成切换 --&gt;&lt;!--local 命令,会在目标文件夹中生成 .python-version 文件, 文件内容是 venv3.6.8, 这样只要进入目录就会自动激活环境 --&gt;pyenv activate venv3.6.8pyenv local venv3.6.8&lt;!--查看pip 安装目录 --&gt;pip --version&lt;!--更新pyenv --&gt;cd ~/.pyenv 或者 cd $(pyenv root)git pull&lt;!--卸载 pyenv--&gt;1. 要删除环境变量2. rm -rf ~/.pyenv&lt;!--继续配置环境..., 在另一个窗口中将当前docker 保存成镜像, 方便以后使用 --&gt;docker commit 8bacc8c47607(docker ps.pid) centos_pyenv_368","link":"/2019/08/28/env_py/"},{"title":"第一次为开源项目贡献pull request ,并被作者采用","text":"第一次为开源项目贡献pull request ,并被作者采用项目地址: Shelnutt2/db2struct 123456789 在golang的学习实践中用到了 ORM框架 GORM, 是一个优秀的开源框架, star人数很高, 在编写与之对应的mode对象时, 就自然遇到了由mysql数据表生成model的需求,在github上找到这 Shelnutt2/db2struct 这个开源项目, 太感谢作者了, 解决了这一痛点问题. 随着对代码的深入,发现db2struct 还可以有两点改进, 所以有了此次的修改,以及pull request , 分两次解决了如下的改进, 作者也有nice,并最终合并的pr . 1 由table生成的model中的字段默认是按字段名排序的, 我们更希望的是以数据表ddl 的顺序为准 2 model 的tag 并未指定column ,这样在遇到非默认字段名规则时会关联失败 3 还有一个小改进,就是把ddl的comment 添加到model中","link":"/2020/12/08/first-pr/"},{"title":"使用itsdangerous生成临时身份令牌","text":"使用itsdangerous生成临时身份令牌在需要身份验证的场景中,可以利用token , 主要流程是由email 向用户下发token, 用户收到邮件证明是本人, 用户点击带有token的链接地址,将token上传后后台 , 后台验证token, 从token中解析出用户信息, 完成一个完整的用户身份验证 12345678910111213import itsdangeroussalt='111't=itsdangerous.TimedJSONWebSignatureSerializer(salt, expires_in=20)res= t.dumps({'sid':'flight'})&gt;&gt;&gt; 'eyJhbGciOiJIUzI1NiIsImV4cCI6MTU2NjE5NDQwOSwiaWF0IjoxNTY2MTk0Mzg5fQ.eyJzaWQiOiJmbGlnaHQifQ.z-56NiU93Jvuus4dezdBcCmveVEBFaqCyHShJPjvgxs't.loads(tes)&gt;&gt;&gt; {u'sid': u'flight'} &lt;!--过期或改变令牌的任意字符 将失败--&gt;SignatureExpired: Signature expiredBadSignature: Signature 'GCkAmN6DEOW_oUteJStX8N93W99z_RqMcAOvINpsQd8a' does not match","link":"/2019/08/19/flask_123/"},{"title":"Flask 请求处理流程","text":"123456789101112131415161718192021sockerserver.py.BaseServer.server_forever._handle_request_noblock() .process_request.finish_request() .BaseRequestHandle.__init__().handle() werkzeug.serving.py.WSGIRequestHandler.BaseHTTPRequestHandler.handle().handle_one_request().parse_requests().run_wsgi() .execute(app) werkzeug.debug.DebuggedApplication.__call__().Request(environ).response(environ, start_response) werkzeug.serving.execute(for data in application_iter:).__call__().run_wsgi() .wsgi_app().request_contex() flask.ctx.py.push().app_ctx.push(**match_request会将当前请求的地址request.url 用正则解析成路由配置表中的数据及参数 **).session_interface.open_session(app, request) flask.full_dispatch_request().preprocess_request() .dispatch_request().view_functions('业务处理') .finalize_request(rv).make_response() .process_response(response).session_interface.save_session() werkzeug.wsgi_app().return response() .ctx.auto_pop(error) .shutdown_request(request)","link":"/2019/09/05/flask_request_process123/"},{"title":"利用有缓冲通道写满时阻塞的特点来控制协程的并发数量","text":"利用有缓冲通道写满时阻塞的特点来控制协程的并发数量12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364type LineGraber struct { //最多允许n个并发同时执行 ConcurrentNum int `json:&quot;concurrent_num&quot;`}func (grab LineGraber) Work() {// &quot;work start&quot;//最少5个协程一起工作concurrentNum := grab.ConcurrentNumif concurrentNum &lt;= 0 { concurrentNum = 5}// sem通道容量限制了并发的协程数sem := make(chan struct{}, concurrentNum)// 准备待处理的任务列表 taskLst := grab.buildTaskLst()// 接口任务处理结果的通道chanRespv := make(chan string, len(taskLst))total := len(taskLst)// log info fmt.Sprintf(&quot;tasksize:%d&quot;, total) var wg sync.WaitGroupfor idx, key := range taskLst { wg.Add(1) go func(taskv string, i int) { // 确保 wg.Done() (与add对应), // &lt;-sem, 从semchan中取出(与下面 sem&lt;- struct{}{}对应) defer func() { wg.Done() &lt;-sem }() sem &lt;- struct{}{} // 真实业务逻辑部分 // 方法中要将结果写入到chanRespv // log info i, taskv grab.processTask(taskv, oneproxy, chanRespv) }(key, idx)}wg.Wait()close(chanRespv)// range 可以从已经关闭的chan 中读取原有数据, 并退出 for respv := range chanRespv { // log info read from chanResp var respResult RespResult err := json.Unmarshal([]byte(respv), &amp;respResult) if err != nil { // log error decode异常 continue } // process ... }// log info (&quot;work done&quot;)} 12345678910111213141516171819202122232425// 以上方法中在 wg.Wait之后才开始接收 chanRespv ,其实还可以优化\\尽早提前处理chanRespv(可以及时读取到结果,避免所有任务完成后才读取到结果的情况), 只需新启协程在wg.Wait 之前接收处理 . // 要增加另外一个通道, 控制完成并退出的信号// 在wg.wait 之前 chanSignal := make(chan interface{})go func() { for { select { case result, ok := &lt;-limiter.resultChan: common.ZLogger.Info(&quot;done&quot;, zap.Any(&quot;result&quot;, result)) if !ok { common.ZLogger.Info(&quot;result通道关闭,退出当前goroutine&quot;) // 通知主线程,可以继续向下执行了 chanSignal&lt;- 1 return } } }}()// 在程序最后添加 &lt;-chanSignal 1234567891011121314// 业务逻辑处理 // 注意chan 类型是只可写入 chan &lt;- string func (grab LineGraber) processTask(key string, proxy string, outchan chan&lt;- string) { aimUrl := fmt.Sprintf(grap_base_url, key) respv, err := doget... if err != nil { // log error ... } //log info ... outchan &lt;- respv}","link":"/2020/12/16/go1-goroutinepool/"},{"title":"自实现 Goroutine pool","text":"自实现 Goroutine pool1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192// limiter.go package limiterimport ( &quot;fmt&quot; &quot;go.uber.org/zap&quot; &quot;station.grab/src/common&quot; &quot;sync&quot; &quot;time&quot;)const ( // MinimaLimit is the minimal concurrency limit MinimaLimit = 5)// Job is an interface for add jobs.type Job interface { Run() (resp string, err error)}// EasyLimiter objecttype EasyLimiter struct { semp chan struct{} // 控制并发的chan wg sync.WaitGroup // waitGroup 用于等待协程执行完成, 并关闭通道\\清理资源 jobChan chan Job // Job 队列(实现接口即可, 解耦了任务的具体实现) resultChan chan interface{} // job执行结果队列}func NewEasyLimiter(taskCount, limit int) *EasyLimiter { if limit &lt;= MinimaLimit { limit = MinimaLimit } c := &amp;EasyLimiter{ semp: make(chan struct{}, limit), resultChan: make(chan interface{}, taskCount), jobChan: make(chan Job, taskCount), } // 创建后马上就监听job队列 // job队列中有数据且semp队列未满 (满了会阻塞,以此来实现并发控制), 则取出job对象, 交给单独协程处理 go func() { for job := range c.jobChan { //c.semp &lt;- struct{}{} select { case c.semp &lt;- struct{}{}: case &lt;-time.After(time.Millisecond * 200): common.ZLogger.Info(&quot;goroutine pool full, wait for 200 mis &quot;, zap.Int(&quot;size&quot;, len(c.semp))) } go func(ajob Job) { defer func() { c.wg.Done() &lt;-c.semp }() //common.ZLogger.Info(&quot;开始执行任务&quot;) result, err := ajob.Run() //common.ZLogger.Info(&quot;完成执行任务&quot;) if err != nil { fmt.Printf(&quot;err:%v&quot;, err) } c.resultChan &lt;- result }(job) } common.ZLogger.Info(&quot;task队列关闭&quot;) }() return c}func (c *EasyLimiter) AddJob(job Job) { c.wg.Add(1) c.jobChan &lt;- job //common.ZLogger.Info(&quot;添加任务&quot;)}func (c *EasyLimiter) Wait() { // 关闭job队列 ,此时已不会再添加 close(c.jobChan) c.wg.Wait() // 关闭result队列,以保证range方式读取chan 程序会正常向下执行 close(c.resultChan)} 测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// limiter_test.go package limiterimport ( &quot;fmt&quot; &quot;go.uber.org/zap&quot; &quot;math/rand&quot; &quot;station.grab/src/common&quot; &quot;testing&quot; &quot;time&quot;)func Max(a int, b int) int { //注意参数和返回值是怎么声明的 if a &gt; b { return a } return b}func RandomInt(n int) int { rand.Seed(time.Now().UnixNano()) v := rand.Intn(n) if v &lt; 1 { v = 1 } return v}type SampleJob struct { total int idx int key string}func (s SampleJob) Run() (resp string, err error) { v := fmt.Sprintf(&quot;job run: %d/%d, %v&quot;, s.idx, s.total, s.key) common.ZLogger.Info(v) //time.Sleep(time.Second*time.Duration(RandomInt(5))) time.Sleep(time.Second * 1) return v, nil}func TestLimiter_Execute(t *testing.T) { fmt.Println(&quot;begin&quot;) total := 20 limiter := NewEasyLimiter(total, 5) for i := 0; i &lt; total; i++ { limiter.AddJob(&amp;SampleJob{ total: total, idx: i, key: &quot;test&quot;, }) } // 控制完成并退出的信号 chanSignal := make(chan interface{}) go func() { for { select { case result, ok := &lt;-limiter.resultChan: common.ZLogger.Info(&quot;read from result chan &quot;, zap.Any(&quot;result&quot;, result)) if !ok { common.ZLogger.Info(&quot;result通道关闭,退出当前goroutine&quot;) chanSignal&lt;- 1 return } } } }() limiter.Wait() &lt;-chanSignal fmt.Println(&quot;done&quot;)}func TestRandom(t *testing.T) { for i := 0; i &lt; 20; i++ { fmt.Println(RandomInt(5)) }}","link":"/2020/12/16/go2-goroutinepool-limiter/"},{"title":"go test","text":"使用TestMain 或自定义Test* 为测试增加前置\\后置方法调用 自定义testFun1, testFun2..方法 , test的t是小写, 这样不会被默认调用 自定义Test*方法, Test的T 大写, 这样可以被go test 工具识别 在Test*方法中按顺序 编写 t.Run(&quot;fun_name&quot;, fun) 编写TestMain方法 , 调用beforeInit, m.Run()(会调用其它Test*方法) afterClear 不写TestMain方法, 直接在 Test*方法中调用也一样,有TestMain方法时, go test 只会识别 TestMain, 所以要显示调用 m.Run() 来调用其它测试方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package testimport ( &quot;bytes&quot; &quot;fmt&quot; &quot;os/exec&quot; &quot;testing&quot;)// cmd.go (写在一个文件中方法读代码)// 待测试方法,func ExecShell(s string) (string, error) { cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, s) var out bytes.Buffer cmd.Stdout = &amp;out err := cmd.Run() if err != nil { return &quot;&quot;, err } return out.String(), nil}func testExecShell(t *testing.T) { t.Log(&quot;testExecShell&quot;) _, err := ExecShell(&quot;ls&quot;) if err != nil { t.Error(err) }}func testFun1(t *testing.T) { t.Log(&quot;testFun1&quot;)}func beforeInit() { fmt.Println(&quot;beforeInit&quot;)}func afterClear() { fmt.Println(&quot;afterClear&quot;)}func TestAll(t *testing.T) { t.Run(&quot;testExec..&quot;, testExecShell) t.Run(&quot;testfun1&quot;, testFun1)}// 在测试中增加前置/后置函数调用的方法, 思路: 自定义测试的新入口,// 1 自定义testFun1, testFun2..方法 , test的t是小写, 这样不会被默认调用// 2 自定义Test*方法, Test的T 大写, 这样可以被go test 工具识别// 3 在Test*方法中按顺序 编写 t.Run(&quot;fun_name&quot;, fun)// 4 编写TestMain 方法 , 调用beforeInit, m.Run()(会调用其它Test*方法) afterClear// 当前不写TestMain方法, 直接在 Test*方法中调用也一样func TestMain(m *testing.M) { fmt.Println(&quot;TestMain&quot;) beforeInit() m.Run() afterClear() //m.Run()} 输出 1234567891011121314151617// go test -v --------------------- TestMainbeforeInit=== RUN TestAll=== RUN TestAll/testExec.. cmd_test.go:25: testExecShell=== RUN TestAll/testfun1 cmd_test.go:33: testFun1--- PASS: TestAll (0.01s) --- PASS: TestAll/testExec.. (0.01s) --- PASS: TestAll/testfun1 (0.00s)PASSafterClearok com.huoli.saas-manager/src/common/util/test 0.022s","link":"/2020/12/29/go3-test/"},{"title":"go test -v","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/08/07/hello-world/"},{"title":"singleflight在并发场景下保护下游业务","text":"singleflight 使用场景 针对同一业务的同一批请求(需自定义缓存的 key),只放一个请求去执行，其他等待结果(和普通缓存还不一样), 可以在不使用缓存的情况下,保护下游业务； 例如 1：在有缓存的数据读取场景中,缓存过期失效时且大并发场景中,瞬间会有大量请求压到数据库,当设置上缓存后才会恢复.但如果去数据库当中查询数据\\内存中计算组装\\设置缓存等操作耗时稍长,同样会存在很大的风险，瞬间的巨量数据库访问,可能会使数据库异常。 例如 1：同上,在无缓存的场景中, 如果一个业务完成处理需要 1s, 100 并发情况下, 这 1s 内都会被到服务器执行, 用 singleflight 只会有一个请求被真正处理, 其它的会等 1s(第一个请求处理完成),直接取第一个请求的处理结果 .golang singleflight 用武之地,杨锡坤 2017-09-17如果每个请求都落到下游服务，通常会导致下游服务瞬时负载升高。如果使用缓存，如何判断当前接口请求的内容需要缓存下来？缓存的过期、更新问题？ 12345678910111213141516171819202122232425// 实现原理func (g *Group) Do(key string, fn func() (interface{}, error)) (interface{}, error) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { g.mu.Unlock() c.wg.Wait() //其他的请求阻塞 return c.val, c.err } c := new(call) c.wg.Add(1) g.m[key] = c g.mu.Unlock() c.val, c.err = fn() //第一个去执行调用 c.wg.Done() //同一批都返回 g.mu.Lock() delete(g.m, key) g.mu.Unlock() return c.val, c.err} 12345678910111213141516171819202122232425262728293031323334// samplefunc TestDoDupSuppress(t *testing.T) { var g singleflight.Group var calls int32 fn := func() (interface{}, error) { fmt.Printf(&quot;inprocess %d\\n&quot;, calls) atomic.AddInt32(&amp;calls, 1) // 模拟耗时 time.Sleep(time.Second * 1) // 回写返回结果 return &quot;ok&quot;, nil } const n = 30 var wg sync.WaitGroup for i := 0; i &lt; n; i++ { wg.Add(1) go func(j int) { // n个协程同时调用了g.Do，fn中的逻辑只会被一个协程执行 fmt.Printf(&quot;before request %d\\n&quot;, j) v, err := g.Do(&quot;key&quot;, fn) fmt.Printf(&quot;after request %d, %#v\\n&quot;, j, v) if err != nil { fmt.Printf(&quot;Do error: %v\\n&quot;, err) } wg.Done() }(i) } wg.Wait() fmt.Printf(&quot;done calls= %d\\n&quot;, calls)}","link":"/2021/01/07/go4-singleflight/"},{"title":"常见的Web攻击手段之CSRF攻击","text":"安全|常见的Web攻击手段之CSRF攻击(转载) 转载自简书 对于常规的Web攻击手段，如XSS、CRSF、SQL注入、（常规的不包括文件上传漏洞、DDoS攻击）等，防范措施相对来说比较容易，对症下药即可，比如XSS的防范需要转义掉输入的尖括号，防止CRSF攻击需要将cookie设置为httponly，以及增加session相关的Hash token码 ，SQL注入的防范需要将分号等字符转义，等等做起来虽然筒单，但却容易被忽视，更多的是需要从开发流程上来予以保障（这句话是给技术管理者的建议），以免因人为的疏忽而造成损失。 一、CSRF介绍CSRF攻击的全称是跨站请求伪造（ cross site request forgery)，是一种对网站的恶意利用，尽管听起来跟XSS跨站脚本攻击有点相似，但事实上CSRF与XSS差别很大，XSS利用的是站点内的信任用户，而CSRF则是通过伪装来自受信任用户的请求来利用受信任的网站。你可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义向第三方网站发送恶意请求。 CRSF能做的事情包括利用你的身份发邮件、发短信、进行交易转账等，甚至盗取你的账号。 1.1、CRSF攻击原理 CRSF攻击原理 首先用户C浏览并登录了受信任站点A； 登录信息验证通过以后，站点A会在返回给浏览器的信息中带上已登录的cookie，cookie信息会在浏览器端保存一定时间（根据服务端设置而定）； 完成这一步以后，用户在没有登出（清除站点A的cookie）站点A的情况下，访问恶意站点B； 这时恶意站点 B的某个页面向站点A发起请求，而这个请求会带上浏览器端所保存的站点A的cookie； 站点A根据请求所带的cookie，判断此请求为用户C所发送的。 因此，站点A会报据用户C的权限来处理恶意站点B所发起的请求，而这个请求可能以用户C的身份发送 邮件、短信、消息，以及进行转账支付等操作，这样恶意站点B就达到了伪造用户C请求站点 A的目的。受害者只需要做下面两件事情，攻击者就能够完成CSRF攻击： 登录受信任站点 A，并在本地生成cookie； 在不登出站点A（清除站点A的cookie）的情况下，访问恶意站点B。 很多情况下所谓的恶意站点，很有可能是一个存在其他漏洞（如XSS）的受信任且被很多人访问的站点，这样，普通用户可能在不知不觉中便成为了受害者。 1.2、攻击举例假设某银行网站A以GET请求来发起转账操作，转账的地址为www.xxx.com/transfer.do?accountNum=l000l&amp;money=10000，参数accountNum表示转账的账户，参数money表示转账金额。而某大型论坛B上，一个恶意用户上传了一张图片，而图片的地址栏中填的并不是图片的地址，而是前而所说的砖账地址：&lt;img src=&quot;http://www.xxx.com/transfer.do?accountNum=l000l&amp;money=10000&quot;&gt;当你登录网站A后，没有及时登出，这时你访问了论坛B，不幸的事情发生了，你会发现你的账号里面少了10000块...为什么会这样呢，在你登录银行A时，你的浏览器端会生成银行A的cookie，而当你访问论坛B的时候，页面上的标签需要浏览器发起一个新的HTTP请求，以获得图片资源，当浏览器发起请求时，请求的却是银行A的转账地址www.xxx.com/transfer.do?accountNum=l000l&amp;money=10000，并且会带上银行A的cookie信息，结果银行的服务器收到这个请求后，会以为是你发起的一次转账操作，因此你的账号里边便少了10000块。当然，绝大多数网站都不会使用GET请求来进行数据更新，因此，攻击者也需要改变思路，与时俱进。假设银行将其转账方式改成POST提交，而论坛B恰好又存在一个XSS漏洞，恶意用户在它的页面上植入如下代码： 12345678&lt;form id=&quot;aaa&quot; action=&quot;http://www.xxx.com/transfer.do&quot; metdod=&quot;POST&quot; display=&quot;none&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;accountNum&quot; value=&quot;10001&quot;/&gt; &lt;input type=&quot;text&quot; name=&quot;money&quot; value=&quot;10000&quot;/&gt;&lt;/form&gt;&lt;script&gt; var form = document.forms('aaa'); form.submit();&lt;/script&gt; 如果你此时恰好登录了银行A，且没有登出，当你打开上述页面后，脚本会将表单aaa提交，把accountNum和money参数传递给银行的转账地址http://www.xxx.com/transfer.do，同样的，银行以为是你发起的一次转账会从你的账户中扣除10000块。当然，以上只是举例，正常来说银行的交易付款会有USB key、验证码、登录密码和支付密码等一系列屏障，流程比上述流程复杂得多，因此安全系数也高得多。 1.3、CSRF的防御1、尽量使用POST，限制GETGET接口太容易被拿来做CSRF攻击，看上面示例就知道，只要构造一个img标签，而img标签又是不能过滤的数据。接口最好限制为POST使用，GET则无效，降低攻击风险。当然POST并不是万无一失，攻击者只要构造一个form就可以，但需要在第三方页面做，这样就增加暴露的可能性。2、将cookie设置为HttpOnlyCRSF攻击很大程度上是利用了浏览器的cookie，为了防止站内的XSS漏洞盗取cookie,需要在cookie中设置“HttpOnly”属性，这样通过程序（如JavaScript脚本、Applet等）就无法读取到cookie信息，避免了攻击者伪造cookie的情况出现。在Java的Servlet的API中设置cookie为HttpOnly的代码如下：response.setHeader( &quot;Set-Cookie&quot;, &quot;cookiename=cookievalue;HttpOnly&quot;);3、增加tokenCSRF攻击之所以能够成功，是因为攻击者可以伪造用户的请求，该请求中所有的用户验证信息都存在于cookie中，因此攻击者可以在不知道用户验证信息的情况下直接利用用户的cookie来通过安全验证。由此可知，抵御CSRF攻击的关键在于：在请求中放入攻击者所不能伪造的信息，并且该信总不存在于cookie之中。鉴于此，系统开发人员可以在HTTP请求中以参数的形式加入一个随机产生的token，并在服务端进行token校验，如果请求中没有token或者token内容不正确，则认为是CSRF攻击而拒绝该请求。假设请求通过POST方式提交，则可以在相应的表单中增加一个隐藏域：&lt;input type=&quot;hidden&quot; name=&quot;_toicen&quot; value=&quot;tokenvalue&quot;/&gt;token的值通过服务端生成，表单提交后token的值通过POST请求与参数一同带到服务端，每次会话可以使用相同的token，会话过期，则token失效，攻击者因无法获取到token，也就无法伪造请求。在session中添加token的实现代码： 12345HttpSession session = request.getSession();Object token = session.getAttribute(&quot;_token&quot;);if(token == null I I &quot;&quot;.equals(token)) { session.setAttribute(&quot;_token&quot;, UUID.randomUUIDO .toString());} 4、通过Referer识别根据HTTP协议，在HTTP头中有一个字段叫Referer，它记录了该HTTP请求的来源地址。在通常情况下，访问一个安全受限的页面的请求都来自于同一个网站。比如某银行的转账是通过用户访问http://www.xxx.com/transfer.do页面完成的，用户必须先登录www.xxx.com，然后通过单击页面上的提交按钮来触发转账事件。当用户提交请求时，该转账请求的Referer值就会是提交按钮所在页面的URL（本例为www.xxx. com/transfer.do）。如果攻击者要对银行网站实施CSRF攻击，他只能在其他网站构造请求，当用户通过其他网站发送请求到银行时，该请求的Referer的值是其他网站的地址，而不是银行转账页面的地址。因此，要防御CSRF攻击，银行网站只需要对于每一个转账请求验证其Referer值即可，如果是以www.xx.om域名开头的地址，则说明该请求是来自银行网站自己的请求，是合法的；如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。取得HTTP请求Referer：String referer = request.getHeader(&quot;Referer&quot;); 二、总结CSRF攻击是攻击者利用用户的身份操作用户帐户的一种攻击方式，通常使用Anti CSRF Token来防御CSRF攻击，同时要注意Token的保密性和随机性。并且CSRF攻击问题一般是由服务端解决。注：文章大部分内容来源于《大型分布式网站架构 设计与实践》一书。","link":"/2019/08/31/httponly/"},{"title":"json 格式化 datetime, date","text":"json.dumps() 对datetime.datetime, datetime.date类型数据无法识别会报错, 需要自定义encoder 来解决在学习flask的源码中,了解了偏函数 ,可以创建原函数的代理,支持预设参数,还可保留原来该用方式 代码如下: 12345678910111213141516from functools import partialclass DateEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, datetime.datetime): return obj.strftime('%Y-%m-%d %H:%M:%S') elif isinstance(obj, datetime.date): return obj.strftime(&quot;%Y-%m-%d&quot;) else: return json.JSONEncoder.default(self, obj)json_dump=partial(json.dumps, ensure_ascii=False, cls=DateEncoder) 调用: 1234567891011121314151617181920212223242526import copyclass User(object): def __init__(self, id, sname): self.id=id self.sname=sname self.time=datetime.datetime.now() self.sname_zh='汉字' def __repr__(self): self_dict = copy.deepcopy(self.__dict__) return json_dump(self_dict, indent=2 )print User(1, 'admin')&gt;&gt;&gt; { &quot;time&quot;: &quot;2019-08-13 14:04:21&quot;, &quot;sname&quot;: &quot;admin&quot;, &quot;id&quot;: 1, &quot;sname_zh&quot;: &quot;汉字&quot;}","link":"/2019/08/13/json-format/"},{"title":"pandas 简单使用","text":"pandas的简单使用记录 创建 由数据库查询创建 自定义数据创建 123456789101112lst=[[1,2,'apple'],[3,4,'banan']]frm=pd.DataFrame(lst, columns=['tag1','tag2', 'tag3'])# 创建子集 , 可指定行区间\\列名frm2=frm.loc[:,['tag1', 'tag3']]# 从表中读取query = Model.query.session.query(Model.local_date, Model.data_source, func.sum(Model.total).label('t'), func.sum(Model.count).label('c'))with AlchemyDbUtil(db, 'statistics') as dbutil: pdf=pd.read_sql(query.statement, dbutil.conn) 查看* head, tail, describle() * 排序 1frame.sort_index(by=['column1'],ascending=False) * 过滤 1234567891011121314151617181920212223# 清除nullfrm3=frm2.dropna(subset=['tag2'])# 一行数据只要有一个字段存在空值即删除frm2.dropna(axis=0, how=&quot;any&quot;)#how 参数可选的值为 any（默认） 或者 all。any 表示一行/列有任意元素为空时即丢弃，all 一行/列所有值都为空时才丢弃。#subset 参数表示删除时只考虑的索引或列名。#thresh参数的类型为整数，它的作用是，比如 thresh=3，会在一行/列中至少有 3 个非空值时将其保留。# 过滤空串frm3=frm3[frm3['tag2']!='']# 按条件过滤frm3=frm3[frm3['tag2']!=frm3['tag1']]# 取toplistfrm_main.nlargest(10, 'cnt')# 分组后取toplist nlargest()的第一个参数就是截取的行数。第二个参数就是依据的列名frm_main.groupby(by=['airline_code', 'iata_code']).apply(lambda x: x.nlargest(1,&quot;cnt&quot;)) * 遍历 |tag1| tag2| cnt| |---|---|---| |6H |C3|6| |8Q |SV|4| 12for idx , item in frm4.iterrows(): print idx, '--', item[0], item[1], item[2] * 导出 to_csv, clipboard ... ![示例](http://ww3.sinaimg.cn/large/006tNc79ly1g60imisu3qj305205vglt.jpg) * 统计 12345# 相当于groupby tag1, tag2 having count(1) &gt;2frm4=frm3.groupby(['tag1', 'tag2']).size().reset_index(name='cnt').query('cnt &gt;2') 修改* 动态生成\\修改列 12345678910111213141516# 由其它列生成frm['tag_short']=frm['tag3'].str[:2]# 由其它函数生成reg_dict={...}for idx in frm.index: frm.loc[idx]['tag_new']=reg_dict.get(frm.loc[idx]['key'], '')# 由lambda表达式生成def apply_func(df): return reg_dict.get(df['key'], '')frm['tag_new']=frm.apply(lambda r:apply_apairline(r), axis=1) * 清除空数据 12# # 可以通过subset参数来删除在age和sex中含有空数据的全部行df4 = df4.dropna(subset=[&quot;age&quot;, &quot;sex&quot;])","link":"/2019/08/14/pandas_123/"},{"title":"py.test 测试,mock","text":"pytest使用方法12345678# 指定测试文件py.test -v test_functions.py# 指定测试目录py.test -v . 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263'''# 目录结构test . ├── __init__.py ├── functions.py # 方法文件 ├── test_app.py # 测试文件 └── test_functions.py # 测试文件'''# functions.pydef multiple(x,y ): return x*y +10def add_and_multiply(x,y ): addition=x+y multi=multiple(x,y) return (addition, multi)# ------------------------# test_functions.pydef test_add_and_multiply(): x,y=3,5 addi, multi=add_and_multiply(x,y ) assert addi==8 assert multi==15# 要mock的方法要写全路径@mock.patch('test.functions.multiple', return_value=15 )def test_add_and_multiply_mock(mock_func): x = 3 y = 5 # 要mock的方法需指定绝对路径 # test.functions.multiple=mock.Mock(return_value=15) addi, multi= add_and_multiply(x, y) print() assert addi == 8 assert multi == 15def test_add_and_multiply_mock2(): x = 3 y = 5 # 要mock的方法需指定绝对路径 test.functions.multiple=mock.Mock(return_value=15) addi, multi= add_and_multiply(x, y) print() assert addi == 8 assert multi == 15 测试'''bash 指定测试文件py.test -v test_functions.py 指定测试目录py.test -v . py.test -v test_functions.pycollected 3 items test_functions.py::test_add_and_multiply FAILED [ 33%]test_functions.py::test_add_and_multiply_mock PASSED [ 66%]test_functions.py::test_add_and_multiply_mock2 PASSED [100%] =============== FAILURES ============___________test_add_and_multiply _____ def test_add_and_multiply(): x,y=3,5 addi, multi=add_and_multiply(x,y ) assert addi==8 assert multi==15 E assert 25 == 15E -25E +15 test_functions.py:21: AssertionError=============== 1 failed, 2 passed in 0.14s =========== 1","link":"/2019/10/24/py-test/"},{"title":"jsonify 支持对象类型","text":"使flask.jsonify 支持对象类型的dumpflask.jsonify 默认支持字典类型的参数, 返回json化的字符串, mimetype 为 application/json, 要注意的是它不支持list入我们自定义的对象 , 下面尝试扩展其功能 flask.wrapers.Response.data with app.test_request_context('/', method='POST') as new_context: print jsonify(a=[1,2,3]).data","link":"/2019/08/27/jsonify/"},{"title":"py37 pandas升级后提示缺少bz2","text":"py37 pandas升级后提示缺少bz2 参考 解决ModuleNotFoundError: No module named '_bz2' 12345在python3环境中默认安装的pandas包是最新的像, 像1.14.. ,而高版本的pandas0.23以后,会将bz2的引用放在头部 , 低版本的会在方法内按需引用 , 所以用高版本,会依赖bz2需要系统级安装依赖来解决,如 yum install bzip2 libbz2-dev , 而对于已经安装好的python环境, 可以参考以下网友分享的方法, 大概步骤如下:1 /python36/lib/python3.6/lib-dynload/x _bz2.cpython-37m-x86_64-linux-gnu.so2 ln -s /usr/lib64/libbz2.so.1.0.6 /usr/lib64/libbz2.so.1.0 'field' is both an index level and a column label, which is ambiguous. 错误 , 需要重建 index1234pandas0.23.1 以后版本,在pandas.merge或其它方法中会报 'field' is both an index level and a column label, which is ambiguous. 错误 , 需要重建 indexsubfrm1 = subfrm1.reset_index(drop=True)","link":"/2020/11/20/py37-pandas-bz2/"},{"title":"转载sqlalchemy 简单使用","text":"转载自jianshu https://www.jianshu.com/p/8d085e2f2657 SQLAlchemy ORM教程之一：Create SQLAlchemy ORM教程之二：Query （本文） SQLAlchemy ORM教程之三：Relationship 这是继SQLAlchemy ORM教程之一：Create后的第二篇教程。在上一篇中我们主要是解决了如何配置ORM系统，建立从类到表的映射的过程，以及如何插入和修改记录。在这个教程中我们主要解决使用的问题。 QuerySession的query函数会返回一个Query对象。query函数可以接受多种参数类型。可以是类，或者是类的instrumented descriptor。下面的这个例子取出了所有的User记录。 123456&gt;&gt;&gt; for instance in session.query(User).order_by(User.id):... print(instance.name, instance.fullname)ed Ed Joneswendy Wendy Williamsmary Mary Contraryfred Fred Flinstone Query也接受ORM-instrumented descriptors作为参数。当多个参数传入时，返回结果为以同样顺序排列的tuples 123456&gt;&gt;&gt; for name, fullname in session.query(User.name, User.fullname):... print(name, fullname)ed Ed Joneswendy Wendy Williamsmary Mary Contraryfred Fred Flinstone Query返回的tuples由KeyedTuple这个类提供，其成员除了用下标访问意外，还可以视为实例变量来获取。对应的变量的名称与被查询的类变量名称一样，如下例： 123456&gt;&gt;&gt; for row in session.query(User, User.name).all():... print(row.User, row.name)&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt; ed&lt;User(name='wendy', fullname='Wendy Williams', password='foobar')&gt; wendy&lt;User(name='mary', fullname='Mary Contrary', password='xxg527')&gt; mary&lt;User(name='fred', fullname='Fred Flinstone', password='blah')&gt; fred 你可以通过label()来制定descriptor对应实例变量的名称 123456&gt;&gt;&gt; for row in session.query(User.name.label('name_label')).all():... print(row.name_label)edwendymaryfred 而对于类参数而言，要实现同样的定制需要使用aliased 123456789&gt;&gt;&gt; from sqlalchemy.orm import aliased&gt;&gt;&gt; user_alias = aliased(User, name='user_alias')SQL&gt;&gt;&gt; for row in session.query(user_alias, user_alias.name).all():... print(row.user_alias)&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt;&lt;User(name='wendy', fullname='Wendy Williams', password='foobar')&gt;&lt;User(name='mary', fullname='Mary Contrary', password='xxg527')&gt;&lt;User(name='fred', fullname='Fred Flinstone', password='blah')&gt; 基本的查询操作除了上面这些之外，还包括OFFSET和LIMIT，这个可以通过Python的array slice来完成。 1234&gt;&gt;&gt; for u in session.query(User).order_by(User.id)[1:3]:... print(u)&lt;User(name='wendy', fullname='Wendy Williams', password='foobar')&gt;&lt;User(name='mary', fullname='Mary Contrary', password='xxg527')&gt; 上述过程实际上只涉及了整体取出的操作，而没有进行筛选，筛选常用的函数是filter_by和filter。其中后者比起前者要更灵活一些，你可以在后者的参数中使用python的运算符。 12345678&gt;&gt;&gt; for name, in session.query(User.name).\\... filter_by(fullname='Ed Jones'):... print(name)ed&gt;&gt;&gt; for name, in session.query(User.name).\\... filter(User.fullname=='Ed Jones'):... print(name)ed 注意Query对象是generative的，这意味你可以把他们串接起来调用，如下： 12345&gt;&gt;&gt; for user in session.query(User).\\... filter(User.name=='ed').\\... filter(User.fullname=='Ed Jones'):... print(user)&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt; 串接的filter之间是与的关系。 常用的filter操作符下面的这些操作符可以应用在filter函数中 equals: 1query.filter(User.name == 'ed') not equals: 1query.filter(User.name != 'ed') LIKE: 1query.filter(User.name.like('%ed%')) IN: 123456query.filter(User.name.in_(['ed', 'wendy', 'jack']))# works with query objects too:query.filter(User.name.in_( session.query(User.name).filter(User.name.like('%ed%')))) NOT IN: 1query.filter(~User.name.in_(['ed', 'wendy', 'jack'])) IS NULL: 1234query.filter(User.name == None)# alternatively, if pep8/linters are a concernquery.filter(User.name.is_(None)) IS NOT NULL: 1234query.filter(User.name != None)# alternatively, if pep8/linters are a concernquery.filter(User.name.isnot(None)) AND: 123456789# use and_()from sqlalchemy import and_query.filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))# or send multiple expressions to .filter()query.filter(User.name == 'ed', User.fullname == 'Ed Jones')# or chain multiple filter()/filter_by() callsquery.filter(User.name == 'ed').filter(User.fullname == 'Ed Jones') OR: 12from sqlalchemy import or_query.filter(or_(User.name == 'ed', User.name == 'wendy')) MATCH: 1query.filter(User.name.match('wendy')) 返回列表(List)和单项(Scalar)很多Query的方法执行了SQL命令并返回了取出的数据库结果。 all()返回一个列表: 1234&gt;&gt;&gt; query = session.query(User).filter(User.name.like('%ed')).order_by(User.id)SQL&gt;&gt;&gt; query.all()[&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt;, &lt;User(name='fred', fullname='Fred Flinstone', password='blah')&gt;] first()返回至多一个结果，而且以单项形式，而不是只有一个元素的tuple形式返回这个结果. 12&gt;&gt;&gt; query.first()&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt; one()返回且仅返回一个查询结果。当结果的数量不足一个或者多于一个时会报错。 1234&gt;&gt;&gt; user = query.one()Traceback (most recent call last):...MultipleResultsFound: Multiple rows were found for one() 没有查找到结果时： 1234&gt;&gt;&gt; user = query.filter(User.id == 99).one()Traceback (most recent call last):...NoResultFound: No row was found for one() one_or_none()：从名称可以看出，当结果数量为0时返回None， 多于1个时报错 scalar()和one()类似，但是返回单项而不是tuple 嵌入使用SQL你可以在Query中通过text()使用SQL语句。例如： 123456789&gt;&gt;&gt; from sqlalchemy import text&gt;&gt;&gt; for user in session.query(User).\\... filter(text(&quot;id&lt;224&quot;)).\\... order_by(text(&quot;id&quot;)).all():... print(user.name)edwendymaryfred 除了上面这种直接将参数写进字符串的方式外，你还可以通过params()方法来传递参数 123&gt;&gt;&gt; session.query(User).filter(text(&quot;id&lt;:value and name=:name&quot;)).\\... params(value=224, name='fred').order_by(User.id).one()&lt;User(name='fred', fullname='Fred Flinstone', password='blah')&gt; 并且，你可以直接使用完整的SQL语句，但是要注意将表名和列明写正确。 1234&gt;&gt;&gt; session.query(User).from_statement(... text(&quot;SELECT * FROM users where name=:name&quot;)).\\... params(name='ed').all()[&lt;User(name='ed', fullname='Ed Jones', password='f8s7ccs')&gt;] 计数Query定义了一个很方便的计数函数count() 12345678910&gt;&gt;&gt; session.query(User).filter(User.name.like('%ed')).count()SELECT count(*) AS count_1FROM (SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_passwordFROM usersWHERE users.name LIKE ?) AS anon_1('%ed',)2 注意上面我们同时列出了实际的SQL指令。在SQLAlchemy中，我们总是将被计数的查询打包成一个子查询，然后对这个子查询进行计数。即便是最简单的SELECT count(*) FROM table，也会如此处理。为了更精细的控制计数过程，我们可以采用func.count()这个函数。 123456&gt;&gt;&gt; from sqlalchemy import funcSQL&gt;&gt;&gt; session.query(func.count(User.name).label('ucnt'), User.name).group_by(User.name).all()SELECT count(users.name) AS count_1, users.name AS users_nameFROM users GROUP BY users.name()[(1, u'ed'), (1, u'fred'), (1, u'mary'), (1, u'wendy')] 为了实现最简单的SELECT count(*) FROM table，我们可以如下调用 12345&gt;&gt;&gt; session.query(func.count('*').label('ucnt')).select_from(User).scalar()SELECT count(?) AS count_1FROM users('*',)4 如果我们对User的主键进行计数，那么select_from也可以省略。 12345&gt;&gt;&gt; session.query(func.count(User.id)).scalar()SELECT count(users.id) AS count_1FROM users()4 在下一篇教程里面我们将会介绍SQLAlchemy对于『关系』的处理方式，以及针对关系的更加复杂的查询。教程的第三部分传送门SQLAlchemy ORM教程之三：Relationship","link":"/2019/08/20/sqlalchemy_123/"},{"title":"vuejs 列表中的元素,要动态绑定多个样式","text":"用以下的方法 没有成功 1:class=&quot;{ done: item.handled==1 , ignore: item.handled==2, ignore2: item.handled==3 }&quot; &gt; 后来发现下面的方法更稳拓些 , 也方便调整 1234567891011121314151617:class=&quot;[gethandle_class(item.handled), getstatus_class(item.status)] &quot;&gt;methods:{ ... gethandle_class: function (handle_v) { return { &quot;1&quot;: &quot;done&quot;, &quot;2&quot;: &quot;ig&quot;, &quot;3&quot;: &quot;ig&quot;, }[handle_v] }, ... }","link":"/2019/09/20/vue-class/"},{"title":"BundleAnalyzer Webpack externals配置,优化chunk-vendor大小,提高初始加载速度","text":"调整了很多次终于见到效果 , 发现最根本的问题在于 被external的包是否依赖Vue, 如果依赖就要把Vue先加external 123456789101112131415161718192021222324252627vue.config.jsconst { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');module.exports = { publicPath: '/saas-manager', // 只用加以下节点 , main.js当中不用调整 configureWebpack: { externals: { // 使用elementui 必须要先中vue(因为elementui依赖vue, 而在html文件中这两个资源也必需写在&lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 之前 ), vue: 'Vue', 'element-ui': 'ELEMENT', }, }, // 更改编译输出的文件名增加hashcode , 以强制浏览器无法缓存, 保证每次修改能及时看到效果 chainWebpack: (config) =&gt; { config.output.filename('js/[name].[hash:6].js') .chunkFilename('js/[name].[hash:6].js') .end(); // 每次yarn serve 新开浏览器显示 BundleAnalyzer(各资源文件大小占比) config .plugin('webpack-bundle-analyzer') .use(BundleAnalyzerPlugin) .init((Plugin) =&gt; new Plugin()); js文件未做任何调整 123456789101112131415161718192021222324main.js import Vue from 'vue';import ElementUI from 'element-ui';import axios from 'axios';import VueAxios from 'vue-axios';import elementUtils from 'vue-element-utils';import App from './App.vue';import router from './router';import store from './store';// 以下两个资料在index.html 中引用csn资源, 以减少打包后的文件大小// import 'element-ui/lib/theme-chalk/index.css';// import 'bootstrap/dist/css/bootstrap.min.css';Vue.config.productionTip = false;Vue.use(ElementUI, { size: 'small', zIndex: 3000,}); 12345678910111213141516index.html&lt;head&gt; // 外部css &lt;link href=&quot;https://cdn.bootcdn.net/ajax/libs/element-ui/2.14.1/theme-chalk/index.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;!-- bootstrap3 会有graph,所以使用bs3 --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.css&quot;&gt;&lt;/head&gt;&lt;body&gt;// 外部js &lt;script src=&quot;https://cdn.bootcdn.net/ajax/libs/vue/2.6.11/vue.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.bootcdn.net/ajax/libs/element-ui/2.14.1/index.js&quot;&gt;&lt;/script&gt;...&lt;div id=&quot;app&quot;&gt;&lt;/div&gt;&lt;/body&gt;","link":"/2021/01/25/vue-webpacket-externals/"}],"tags":[{"name":"dict, hash","slug":"dict-hash","link":"/tags/dict-hash/"},{"name":"数据库,备份","slug":"数据库-备份","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%A4%87%E4%BB%BD/"},{"name":"celery ,  flower , redis","slug":"celery-flower-redis","link":"/tags/celery-flower-redis/"},{"name":"pyenv, python3.6 ,虚拟环境","slug":"pyenv-python3-6-虚拟环境","link":"/tags/pyenv-python3-6-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"},{"name":"pr, pull request","slug":"pr-pull-request","link":"/tags/pr-pull-request/"},{"name":"web, flask ,token","slug":"web-flask-token","link":"/tags/web-flask-token/"},{"name":"flask, request","slug":"flask-request","link":"/tags/flask-request/"},{"name":"goroutine go pool 并发 协程","slug":"goroutine-go-pool-并发-协程","link":"/tags/goroutine-go-pool-%E5%B9%B6%E5%8F%91-%E5%8D%8F%E7%A8%8B/"},{"name":"go test TestMain","slug":"go-test-TestMain","link":"/tags/go-test-TestMain/"},{"name":"singleflight goroutine","slug":"singleflight-goroutine","link":"/tags/singleflight-goroutine/"},{"name":"web, csrf ,xss","slug":"web-csrf-xss","link":"/tags/web-csrf-xss/"},{"name":"json ,  partial","slug":"json-partial","link":"/tags/json-partial/"},{"name":"pytest, mock","slug":"pytest-mock","link":"/tags/pytest-mock/"},{"name":"web, flask ,jsonify","slug":"web-flask-jsonify","link":"/tags/web-flask-jsonify/"},{"name":"python3.7, virtualenv , bz2","slug":"python3-7-virtualenv-bz2","link":"/tags/python3-7-virtualenv-bz2/"},{"name":"sqlalchemy, orm","slug":"sqlalchemy-orm","link":"/tags/sqlalchemy-orm/"},{"name":"vuejs, class","slug":"vuejs-class","link":"/tags/vuejs-class/"},{"name":"BundleAnalyzer,  Webpack externals, chunk-vendor","slug":"BundleAnalyzer-Webpack-externals-chunk-vendor","link":"/tags/BundleAnalyzer-Webpack-externals-chunk-vendor/"}],"categories":[]}